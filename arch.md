## 分布式
### 分布式任务
[dkron](https://github.com/distribworks/dkron)


### 分布式锁

### 一致性算法
raft
Gossip

### 一致性哈希

### zk，etcd，consul
**zk**

**etcd**

**consul**



### 分布式id
https://www.cnblogs.com/li-peng/p/12124249.html
https://github.com/micro/go-micro
https://github.com/micro/micro
https://github.com/smallnest/rpcx
https://github.com/go-kit/kit
https://colobu.com/2020/02/21/ID-generator/





## mq的区别

### 模式：

#### 消息队列模式： 
消息只能由一个消费者消费
消息队列除了提供解耦功能之外，它还能够对生产者和消费者进行独立的伸缩



#### 发布/订阅模式：
单个消息可以被多个订阅者并发的获取和处理

临时（ephemeral）订阅：
这种订阅只有在消费者启动并且运行的时候才存在。一旦消费者退出，相应的订阅以及尚未处理的消息就会丢失。
持久（durable）订阅：
这种订阅会一直存在，除非主动去删除。消费者退出后，消息系统会继续维护该订阅，并且后续消息可以被继续处理。

#### rabbitmq
1. 命名队列：然后发布者可以向这个命名队列中发送消息。最后消费者可以通过这个命名队列获取待处理的消息。
2. 消息交换器：发布者可以把消息发布到消息交换器上而不用知道这些消息都有哪些订阅者。
每一个订阅了交换器的消费者都会创建一个队列；然后消息交换器会把生产的消息放入队列以供消费者消费。消息交换器也可以基于各种路由规则为一些订阅者过滤消息。
3. 消费者组：订阅者以组队的方式然后在组内以竞争关系作为消费者去处理某个具体队列上的消息
4. push模式
5. 有消息确认，路由功能比较强大



#### Apache Kafka
1. Apache Kafka不是消息中间件的一种实现。相反，它只是一种分布式流式系统。
2. Kafka没有实现队列这种东西。相应的，Kafka按照类别存储记录集，并且把这种类别称为主题。
Kafka为每个主题维护一个消息分区日志。每个分区都是由有序的不可变的记录序列组成，并且消息都是连续的被追加在尾部。
当消息到达时，Kafka就会把他们追加到分区尾部。默认情况下，Kafka使用轮询分区器（partitioner）把消息一致的分配到多个分区上。
3. Kafka可以改变创建消息逻辑流的行为，确保来自相同逻辑流上的消息映射到相同分区上，这就保证了消息能够按照顺序提供给消费者
4. 消费者通过维护分区的偏移（或者说索引）来顺序的读出消息，然后消费消息。
5. 生产者可以向一个具体的主题发送消息，然后多个消费者组可以消费相同的消息。每一个消费者组都可以独立的伸缩去处理相应的负载。由于消费者维护自己的分区偏移，所以他们可以选择持久订阅或者临时订阅，持久订阅在重启之后不会丢失偏移而临时订阅在重启之后会丢失偏移并且每次重启之后都会从分区中最新的记录开始读取。
6. poll模式读取数据，通过读写指针控制读写的位置，可以保持较多的数据
持久化存储


#### 如何先泽
1. rabbitmq：实时性质，完成确认
2. kafka：高吞吐量



## mongo和mysql的选择

需要报表，事物，用mysql

mongo使用的4大场景
1.非结构化数据，扩展字段非常容易，适合结构易变的场景
2.更高的写入负载。而非事务安全性
3.容易横向扩展：自带sharding
4.自带高可用：自动主从切换

不适合的场景
1.需要事务安全的场景
3.需要负责连表查询





