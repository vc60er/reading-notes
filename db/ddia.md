# DDIA


## 数据存储与检索
### 哈希索引
实现方式：
1. 数据以追加方式写入文件
2. 在内存中通过hash map保存数据在文件中的偏移量
3. 当文件写入一定大小之后，启用新的文件和hash map，关闭老的文件
4. 后台线程对以关闭的老文件执行压缩；丢弃相同key老的数据，保留新的数据，获得新的数据文件和hash map，压缩完成之后替换老的文件和hash map；压缩过后，还可能会对较小的数据文件做合并操作。
5. Value的读取过程，需要先到最新的hash map中找到pos，如果没有继续在次老的hash map中找，找到pos之后，通过pos在对应的数据文件中读取value
6. Value的更新过程，需要在最新的数据文件中追加数据，并且更新最新的hash map
7. Key的删除过程，需要在最新的数据文件中最佳特殊标记（墓碑）
8. 崩溃恢复：
    1. （老的）hash map持久化到磁盘上，便于重启的时候恢复hash map
    2. 写入数据文件的数据，需要附带校验值，便于验证数据的完整性


优点:
1. 数据以追加方式写入，具有较高的写入效率
2. 实现方式简单

缺点:
1. 哈希表需要全部放到内存中，内存占用大
2. 不支持key的范围查询

应用：


### SSTable和LSM-Tree

实现方式:
1. 文件中有序存储key-value对，称之为SSTable（排序字符串表），每个key出现一次
2. 内存中维护有序树（红黑树、AVL数）存储key-value，又称，内存表
3. 数据首先写入到内存的树上，到达一定量之后，在顺序遍历树上的数据，写入到数据文件中，并生成*稀疏内存表*
4. 稀疏内存表存储key和value在文件上的pos，为一段连续的key，只保存第一个key及其pos
5. 读取key的Value时，首选从树上读，然后是数据文件，其次再是次新的数据文件；如果在内存中没有找到对应的key，可以先找到其前后的两个key，读取这两个key直接的所有数据，在从数据中找到需要的key-value
6. 后台线程定期执行合并和压缩。
7. 通过WAL（预写日志）的方式，解决意外奔溃时候丢失内存数据的问题，


这种方式最初被命名为日志结构的合并树（LSM-Tree），是因为它是建立在日志结构得文件系统之上，，后来，基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎

优点：
1. 具有较高的写入效率
2. 采用了稀疏内存表，内存占用较少

缺点：
1. 仍然不支持key的范围查询
2. 较高白分位的读写延迟较高
3. 后台压缩页会消耗点一部分磁盘io
4. 一个键有多个副本，不适合实现事物
5. 

应用：
LevelDB，HBase，Cassandra


### B-Tree

实现方式:
1. 将数据库分解成固定大小的块或页，使用地址或者位置来标识，作为树的结点
2. 页（结点）包含了若干个键和对子页（子结点）的引用，
3. 每个引用负责一个连续范围内的键，引用两侧的键可以指示这个引用范围的边界
4. 叶子结点存储键和值
5. 查询时，从根节点出发，不断找到key可能所在的子页，最终到达叶子结点
6. 写入数据时候，与查询相同的方式定位到合适的叶子结点，再更新或者添加数据。如果，叶子结点空间不够，需要将叶子分裂后，在写入数据。即，将叶子结点分裂成两个叶子结点，分裂出来的新叶子结点的引用添加到父节点合适位置。
7. 通过WAL（预写日志）的方式，解决意外奔溃时候产生孤儿结点的问题
8. 同父的相邻叶子结点会会相互引用，以便于顺序扫描，而不用回到父节点


todo
[] add pic3.6，3.7


### 对比B-tree和LSM-tree读写对比

LSM-tree写入更快：先写入WAL，然后更新内存上的有序树
LSM-tree查询较慢：有可能需要检查不同压缩阶段的多个sstable

B-tree写入较慢：先写入WAL，然后找到数据所在的叶子结点，然后更新叶子结点，有可能产生也分裂
B-tree查询更快: 


## 其他的索引结构

## 事务

### 事务的4个特性
- 原子性：在出错时终止事务，并将部分完成的写入全部丢弃。换句话说，一个事物的多个写入，要不全部成功，要不全部失败，不会出现部分写入成功。
- 一致性：对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等）。例如，对于一个账单系统，账号的贷款余额应和借款余额保持平衡。这种一致性本质上要求应用层来维护状态一致（或者恒等），应用程序有责任正确的定义事务来保持一致性。一致性更多是应用层的属性，应用程序可能借助数据库提供的原子性和隔离性，以达到一致性，但一致性本身并不源于数据库。
- 隔离性：并发执行的多个事务相互隔离，他们不能相互交叉。
- 持久性：事务提交成功之后，便能提供数据持久性保障，即数据不会丢


### 弱隔离级别
- 读-提交
读数据时，只能看到已成功提交的数据
写数据时，只能覆盖以成功提交的数据
解决了数据的脏读，脏写问题
通过行锁防止脏写，使用相同的锁可以防止脏读，但是会带来很多性能损失，一般不这样做

- 快照级别隔离与可重复读

有两个多对象的事务，一个更新数据，一个读取数据，读数据的事务读到了，写事务提交前后的两部分数据，导致读取到的数据集，在后来不可以重复读取到
例如。数据a=1，b=2，事务r，w
```      
         a=1                           b=3
r:   get a                         get b
w:   set a=a+1  set b=b+1  commit

事务r读取到（a，b）=（1，3）
事务w提交之前（a，b）=（1，2），提交之后（a，b）=（2，3）
```

可以通过快照隔离解决此问题，快照隔离是通过mvcc的方式来实现
1. 对要修改的数据加写锁
2. 事务开始时会分配一个递增的事务id:tid
3. 事务对数据修改时，会产生出新的数据版本，版本信息包括：created_by: tid, deleted_by: tid_next_modify_tid, key, value。created_by为产生这个数据版本的事务id，deleted_by为再次修改该版本数据的事务id
5. 被delete的版本，会被垃圾回收进程真正删除

版本可见性：
1. 进行中的事务不可见
2. 已经终止的事务不可见
3. 大于当前事物id的是事务不可见
4. 除此之外，其他事务都可见

疑问：
1. 如果要修改某个的数据已经被修改（deleted_by!=nil）, 会怎样


- 防止更新丢失

原子操作：

set value=value+x

显示加锁：

begin transaction
select \* from t where id=x for update
update t set a=x
commit

原子比较设置：

update t set a=x+1 where a=x



- 写倾斜与幻读
幻读：两个读写事务中，一个事务的写入改变了另一个事务查询结果的现象，称为幻读

例如，事务t1，t2，数据a=1，b=1

```
t1: get a b   if(a+b==2)  set a=0   commit
t2: get a b   if(a+b==2)  set b=0   commit
```

两个事务，都是希望在a+b==2的时候修改数据一部分数据，然后得到a+b==1，但是得到的最后结果是a+b==0

同样的例子常发生于：基于查询结果的两次update，或者两次insert操作

```
t1: ret=get x    if(ret=null)   set x=1
t2: ret=get x    if(ret=null)   set x=1
```

写倾斜：既不是脏写，也不是更新丢失，两个事务更新的是两个不同的对象


### 串行化
























