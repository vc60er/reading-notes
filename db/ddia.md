# DDIA

## 数据存储与检索
### 哈希索引
实现方式:

1. 数据以追加方式写入文件
2. 在内存中通过hash map保存数据在文件中的偏移量
3. 当文件写入一定大小之后，启用新的文件和hash map，关闭老的文件
4. 后台线程对以关闭的老文件执行压缩；丢弃相同key的老数据，保留新的数据，获得新的数据文件和hash map，压缩完成之后替换老的文件和hash map；压缩过后，还可能会对较小的数据文件做合并操作。
5. Value的读取过程，需要先到最新的hash map中找到pos，如果没有，则继续在次新的hash map中找，找到pos之后，通过pos在对应的数据文件中读取value
6. Value的更新过程，需要在最新的数据文件中追加数据，并且更新最新的hash map
7. Key的删除过程，需要在最新的数据文件中最佳特殊标记（墓碑）
8. 崩溃恢复：
    1. 老的hash map持久化到磁盘上，便于重启的时候恢复hash map
    2. 写入数据文件的数据，需要附带校验值，便于验证数据的完整性


优点:

1. 数据以追加方式写入，具有较高的写入效率
2. 实现方式简单

缺点:

1. 哈希表需要全部放到内存中，内存占用大
2. 不支持key的范围查询

应用:


### SSTable和LSM-Tree

实现方式:

1. 文件中有序存储key-value对，称之为SSTable（排序字符串表），每个key出现一次
2. 内存中维护有序树（红黑树、AVL数）存储key-value，又称，内存表
3. 数据首先写入到内存的树上，到达一定量之后，在顺序遍历树上的数据，写入到数据文件中，并生成*稀疏内存表*
4. 稀疏内存表存储key和value在文件上的pos，为一段连续的key，只保存第一个key及其pos
5. 读取key的Value时，首选从树上读，然后是数据文件，其次再是次新的数据文件；如果在内存中没有找到对应的key，可以先找到其前后的两个key，读取文件中这两个key之间的所有数据，再从数据中找到需要的key-value
6. 后台线程定期执行合并和压缩。
7. 通过WAL（预写日志）的方式，解决意外奔溃时候丢失内存数据的问题，

>这种实现方式早期是建立在日志结构的文件系统之上，所以，被命名为日志结构的合并树（LSM-Tree），后来，基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎

优点:

1. 具有较高的写入效率
2. 采用了稀疏内存表，内存占用较少

缺点:

1. 仍然不支持key的范围查询
2. 较高白分位的读写延迟较高
3. 后台压缩页会消耗点一部分磁盘io
4. 一个键有多个副本，不适合实现事物


应用:

LevelDB，HBase，Cassandra


### B-Tree

实现方式:

1. 将数据库分解成固定大小的块或页，使用地址或者位置来标识，作为树的结点
2. 页（结点）包含了若干个键和对子页（子结点）的引用，
3. 每个引用负责一个连续范围内的键，引用两侧的键可以指示这个引用范围的边界
4. 叶子结点存储键和值
5. 查询时，从根节点出发，不断找到key可能所在的子页，最终到达叶子结点
6. 写入数据时候，与查询相同的方式定位到合适的叶子结点，再更新或者添加数据。如果，叶子结点空间不够，需要将叶子分裂后，在写入数据。即，将叶子结点分裂成两个叶子结点，分裂出来的新叶子结点的引用添加到父节点合适位置。
7. 通过WAL（预写日志）的方式，解决意外奔溃时候产生孤儿结点的问题
8. 同父的相邻叶子结点会会相互引用，以便于顺序扫描，而不用回到父节点


todo
[] add pic3.6，3.7


### 对比B-tree和LSM-tree读写对比

- LSM-tree写入更快：先写入WAL，然后更新内存上的有序树
- LSM-tree查询较慢：有可能需要检查不同压缩阶段的多个sstable
- B-tree写入较慢：先写入WAL，然后找到数据所在的叶子结点，然后更新叶子结点，有可能产生也分裂
- B-tree查询更快: 


## 其他的索引结构

todo


## 事务

### 事务的四个特性

- 原子性：在出错时终止事务，并将部分完成的写入全部丢弃。换句话说，一个事物的多个写入，要不全部成功，要不全部失败，不会出现部分写入成功。
- 一致性：对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等）。例如，对于一个账单系统，账号的贷款余额应和借款余额保持平衡。这种一致性本质上要求应用层来维护状态一致（或者恒等），应用程序有责任正确的定义事务来保持一致性。一致性更多是应用层的属性，应用程序可能借助数据库提供的原子性和隔离性，以达到一致性，但一致性本身并不源于数据库。
- 隔离性：并发执行的多个事务相互隔离，他们不能相互交叉。
- 持久性：事务提交成功之后，便能提供数据持久性保障，即数据不会丢


### 弱隔离级别
#### 读-已提交

问题:

- 脏读：数据读取时，读到了未提交的数据
- 脏写：数据写入时，覆盖了未提交的数据


解决办法:

通过行锁防止脏写，使用相同的锁可以防止脏读，但是会带来很多性能损失，一般不这样做



#### 快照级别隔离与可重复读

问题:

不可重复读的问题描述如下:

有两个多对象的事务，一个更新数据，一个读取数据，读数据的事务读到了写事务提交前后的两部分数据，导致读取到的数据集，在后来不可以重复读取到
例如。数据a=1，b=2，事务tr，tw

```txt
          a=1                           b=3
--------------------------------------------          
tr:   get a                         get b
tw:   set a=a+1  set b=b+1  commit
--------------------------------------------
事务tr读取到（a，b）=（1，3）
事务tw提交之前（a，b）=（1，2），提交之后（a，b）=（2，3）
```

解决办法:

可以通过快照隔离解决此问题，快照隔离是通过mvcc的方式来实现，实现方式如下:

1. 对要修改的数据加写锁
2. 事务开始时会分配一个递增的事务id:tid
3. 事务对数据修改时，会增加一个新的数据版本，版本信息包括：{created_by: tid, deleted_by: tid_next_modify_tid, key, value}。created_by为产生这个数据版本的事务id，deleted_by为再次产生这个数据新版本的事务id
5. 被delete的版本，会被垃圾回收进程真正删除

执行中的事务对数据的多个版本的可见性:

1. 进行中的事务不可见。该版本数据的事务还没有结束，其他事物不可以见此版本的数据
2. 已经终止的事务不可见。该版本数据的事务被终止，未完成提交，其他事物不可以见此版本的数据
3. 大于当前事物id的是事务不可见。该版本数据的事务id小于当前事物，则当前事物不可见此版本的数据
4. 除此之外，其他事务都可见

疑问:

1. 如果要修改某个的数据已经被修改（deleted_by!=nil）, 会怎样



todo pic


#### 防止更新丢失

问题:

应用程序从数据库读取某些值，更加应用逻辑做出修改，然后写回新值。在并发环境下，可能出现第一个写入操作被丢失（被覆盖）的问题，比如：两个线程thd1，thd2，都去读取然后修改数据a的值, a=0

```
        a=0         a=1          a=1
----------------------------------------------------------------
thd1:  read a      a=a+1       write a
thd2:  read a      a=a+1                    write a 
----------------------------------------------------------------
        a=0         a=1                       a=1
```

两个线程都对a+1之后，预期结果应该是a=2，可是上面的结果会是a=1。其中thd1写入的值，并没个被thd2读取到，进而thd2覆盖了thd1的值，相当于thd1写入的值被丢掉了

>该问题是并发带来的问题，需要在应用层解决


解决办法:

- 原子操作:
```sql
update t set value=value+x where id=x
```

- 显示加锁:
```sql
begin transaction
select * from t where id=x for update
update t set a=x
commit
```

- 原子比较设置:
```sql
update t set a=x+1 where a=x
```


#### 写倾斜与幻读

问题:

幻读：两个读写事务中，一个事务的写入改变了另一个事务查询结果的现象，称为幻读

例如，事务t1，t2，数据a=1，b=1

```
t1: get a b   if(a+b==2)  set a=0   commit
t2: get a b   if(a+b==2)  set b=0   commit
```

两个事务，都是希望在a+b==2的时候修改数据一部分数据，然后得到a+b==1，但是得到的最后结果是a+b==0

同样的例子常发生于：基于查询结果的两次update，或者两次insert操作

```
t1: ret=get x    if(ret=null)   set x=1
t2: ret=get x    if(ret=null)   set x=2
```

写倾斜：既不是脏写，也不是更新丢失，两个事务更新的是两个不同的对象


解决办法:

- 显示加锁: 使用select for update的方法显示加锁，能够解决两次update导致的幻读问题
- 实体化冲突: 提前实体化(插入数据)会出现竞争的key，将insert转化为update，从而将幻读问题转话为针对数据库具体行的锁冲突问题，能够解决两次insert导致的幻读问题
- 串行化隔离:


### 串行化

串行化的是实现方式有以下几种:

#### 实际串行执行

严格按照串行顺序执行

实现方式:

在一个线程上按照顺序每次执行一个事物

面临的问题:

- 如果事务中需要的数据，大多数情况需要从磁盘上读取，则会严重影响系统的整体性能，
- 对于多次交互的事务，比如，需要应用层，或者用户层，多次向数据库发出sql请求，会严重影响系统的整体性能
- 由于为了解决单线程事务带来的cpu瓶颈，使用对数据分区的办法解决，从而带来跨分区的事务仍然需要加锁执行，最终会严重影响系统的整体性能


局限性:

- 事务必须简短高效，否则一个缓慢的事务会影响到其他事务的执行性能
- 仅限于活动数据完全可以加载到内存的场景。有些很少访问的数据可能会被移动到磁盘，但万一单线程事务需要访问他，就会严重拖累性能
- 写入吞吐量必须足够低，才能在单个cpu上处理；否则就需要采用分区，最好没有跨分区事物。
- 跨分区事物虽然可以支持，但是占比必须很小


#### 两阶段加锁(2PL)

两阶段加锁几乎是近几十年来唯一可行的串行化技术选择。两阶段加锁的两阶段分别指，事务执行之前获取锁，事务执行结束时释放锁。两阶段加锁的锁包含两种锁：共享锁(读锁)，独占锁(写锁)

实现方式:

1. 如果事务要读取对象，则必须获取共享锁，之后，可以多个事务获取该对象的共享锁，但是其他事务不能获取到该对象的独占锁
2. 如果事务要修改对象，则必须获取独占锁，之后，其他事务不能获取到该对象的任何锁
3. 如果先读取对象，后修改对象，则需要将共享锁升级为独占锁，升级到的独占锁等价于直接获取到的独占锁



面临的问题：

- 死锁问题，比如下面这种情况:

```
    read_lock(a)
    read_lock(b)       write_lock(a)    wait_lock(b)    ...
----------------------------------------------------------------------
t1: get a b              set a=0          set b=0       
t2: get a b              set b=0          set a=0       
----------------------------------------------------------------------
    read_lock(a)       write_lock(b)    wait_lock(a)    ...
    read_lock(b)

```

数据会自动检测这种情况，并强制结束其中一个来打破僵局

- 性能问题：锁的获取和释放本身有一定的开销，但公重要的是降低了事务的并发性



其他高级锁：

- 谓词锁: 是指给where的条件能够覆盖得到的所有对象添加锁，这个锁可以是共享锁或者独占锁。这种锁可以解决幻读的问题。
- 索引区间锁: 是谓词锁的简化版，解决了谓词锁可能会造成锁泛滥，影响性能的问题。索引区间锁的实现方式是，将锁附加到查询所使用的索引上，如果没有索引，则会附加到整个表上，这样虽然扩大了锁的范围，但是能够控制锁的数量。



#### 可串行化的快照隔离(SSI)

是一种乐观并发控制技术，如果发生潜在冲突，事务会继续执行而不是终止，而当事务提交到的时候，会检查是否确实发生了冲突。可串行化的快照隔离是在快照隔离的基础上，SSI新增加了相关算法来检测写入之间的串行化冲突，从而决定终止哪些事务。

在快照隔离环境下存在幻读问题，根本原因是，事务的查询结果被另一个事务修改。所以检测查询结果是否发生改变是SSI的核心目标。检测查询结果是否发生变化，有以下两种情况:

- 检测是否读取了过期的MVCC对象: 
 
事务提交时，检查是否存在一些当初被忽略的些写操作现在已经完成了提交，如果是则必须终止当前事务。

- 检测写是否影响到了之前的读:

类似索引区间锁的技术，读取时会在索引上记录一些额外信息，当另一个事务修改时，会检查索引是否存在读该目标数据的其他事务，如果存在，会记录额外数据，读事务会在提交的时候会收到通知，他读取到的数据已被修改，读事务将被终止。










